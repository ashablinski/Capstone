{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Collaborative_Neural_Rec_Sys.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiQDeKx9t7lD",
        "colab_type": "text"
      },
      "source": [
        "# **NEURAL COLLABORATIVE RECOMMENDER SYSTEM FOR MOVIES** \n",
        "\n",
        "![Neural Nets](https://i.imgur.com/sJBTWPN.png?1!)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnIFzLcolkxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d4988a7-b061-4897-b6b5-78fb4d6eb312"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "print(\"Run on TensorFlow 2.x\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run on TensorFlow 2.x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_WB-oukwREC",
        "colab_type": "text"
      },
      "source": [
        "# I. Initial Stage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWpeh8XKVR_w",
        "colab_type": "text"
      },
      "source": [
        "IMPORT LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ostjpiswhkW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fa02b865-7926-4ad0-e062-6e172a4f0a0d"
      },
      "source": [
        "# Import Dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import initializers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# The following lines adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "# The following line improves formatting when ouputting NumPy arrays.\n",
        "np.set_printoptions(linewidth = 200)\n",
        "\n",
        "print(\"--\" * 17)\n",
        "print(\"ALL MODULES IMPORTED AND ACTIVATED\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------\n",
            "ALL MODULES IMPORTED AND ACTIVATED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX0-0rIRVW3X",
        "colab_type": "text"
      },
      "source": [
        "INITIALIZE EAGER EXECUTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia2YW3yPVbwx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a9a861f-3b87-4ed5-b2f6-fea1689ad88e"
      },
      "source": [
        "# After eager execution is enabled, operations are executed as they are defined, \n",
        "# and Tensor objects hold concrete values.\n",
        "\n",
        "tf.compat.v1.enable_eager_execution(\n",
        "    config=None, device_policy=None, execution_mode=None\n",
        ")\n",
        "print(\"EAGER EXECUTION ENABLED\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EAGER EXECUTION ENABLED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnA8yZc4v-7e",
        "colab_type": "text"
      },
      "source": [
        "LOADING DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-ml2vetWIMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "81732bed-8240-4ebc-90fa-8a9c8e208094"
      },
      "source": [
        "# Mounting Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Changing Directory\n",
        "%cd /content/gdrive/My\\ Drive/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lF9J29ewAdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading Clean Data\n",
        "ratings_df = pd.read_csv('/content/gdrive/My Drive/CKME 136 Data Analytics - Capstone - Art Shablinski - 501009387/DATA/CLEAN DATA/ratings_df.csv')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaF5UnQbRCcs",
        "colab_type": "text"
      },
      "source": [
        "# II. Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFWRtOVqRjTd",
        "colab_type": "text"
      },
      "source": [
        "ENCODING VECTORS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ6YCZhVRf-w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d61438ff-c4bc-497f-b927-af8e36c16458"
      },
      "source": [
        "# Encoding user vectors\n",
        "user_ids = ratings_df[\"userId\"].unique().tolist()\n",
        "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
        "\n",
        "# Encoding movie vectors\n",
        "movie_ids = ratings_df[\"movieId\"].unique().tolist()\n",
        "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
        "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
        "\n",
        "ratings_df[\"user\"] = ratings_df[\"userId\"].map(user2user_encoded)\n",
        "ratings_df[\"movie\"] = ratings_df[\"movieId\"].map(movie2movie_encoded)\n",
        "\n",
        "num_users = len(user2user_encoded)\n",
        "num_movies = len(movie_encoded2movie)\n",
        "ratings_df[\"rating\"] = ratings_df[\"rating\"].values.astype(np.float32)\n",
        "\n",
        "# min and max values will be used to normalize the ratings later\n",
        "min_rating = min(ratings_df[\"rating\"])\n",
        "max_rating = max(ratings_df[\"rating\"])\n",
        "\n",
        "print(\n",
        "    \"Total Number of Users: {}, Total Number of Rated Movies: {}, Min Rating: {}, Max Rating: {}\".format(\n",
        "        num_users, num_movies, min_rating, max_rating\n",
        "    )\n",
        ")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of Users: 138493, Total Number of Rated Movies: 26744, Min Rating: 0.5, Max Rating: 5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEF0HxCsRnIb",
        "colab_type": "text"
      },
      "source": [
        "DATA SPLIT AND SCALING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go0sG4mZl3ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Randomize classes to improve Model generalizability\n",
        "df = ratings_df.sample(frac=1, random_state=23)\n",
        "x = ratings_df[[\"user\", \"movie\"]].values\n",
        "\n",
        "# Normalize the labels between 0 and 1 to prevent gradients from exploding, and\n",
        "# making learning of parameters more stable\n",
        "y = ratings_df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
        "\n",
        "# Splitting the data to train on 70% of the data and validating on 30%\n",
        "train_indices = int(0.7 * df.shape[0])\n",
        "x_train, x_val, y_train, y_val = (\n",
        "    x[:train_indices],\n",
        "    x[train_indices:],\n",
        "    y[:train_indices],\n",
        "    y[train_indices:],\n",
        ")"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RhOhwLo7EA3",
        "colab_type": "text"
      },
      "source": [
        "# III. Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFPe0q--iAwF",
        "colab_type": "text"
      },
      "source": [
        "DEFINE AND COMPILE THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkKblL5ciBHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_SIZE = 50\n",
        "\n",
        "class CNRC(keras.Model):\n",
        "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "        super(CNRC, self).__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.user_bias = layers.Embedding(num_users, 1)\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        user_bias = self.user_bias(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        movie_bias = self.movie_bias(inputs[:, 1])\n",
        "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
        "        # Add all the components (including bias)\n",
        "        x = dot_user_movie + user_bias + movie_bias\n",
        "        # The sigmoid activation forces the rating to between 0 and 1\n",
        "        return tf.nn.sigmoid(x)\n",
        "\n",
        "model = CNRC(num_users, num_movies, EMBEDDING_SIZE)\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001), metrics=[\"Precision\", \"Recall\"]\n",
        ")"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38bmwePdiPlF",
        "colab_type": "text"
      },
      "source": [
        "TRAINING THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT99Af2JiR8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Destroys the current TF graph and session, and creates a new one.\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Training our Neural Network\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=800,\n",
        "    epochs=5,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDiyv9-q7SaD",
        "colab_type": "text"
      },
      "source": [
        "SAVING AND SUMMARIZING THE MODEL PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13sXYNz_7Rxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('CNRS')\n",
        "new_model = keras.models.load_model('CNRS')\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S31IccET7MP7",
        "colab_type": "text"
      },
      "source": [
        "# IV. Evaluation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL7mCShCbVXV",
        "colab_type": "text"
      },
      "source": [
        "DEFINE A PLOTTING FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjsNATjlbX-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73c98475-7f90-4347-a0bb-42d5e4cbc84f"
      },
      "source": [
        "def plot_curve(epochs, hist, list_of_metrics):\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Value\")\n",
        "\n",
        "  for m in list_of_metrics:\n",
        "    x = hist[m]\n",
        "    plt.plot(epochs[1:], x[1:], label=m)\n",
        "\n",
        "  plt.legend()\n",
        "\n",
        "print(\"Loaded the plot_curve function.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded the plot_curve function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWr__Gg3Fg23",
        "colab_type": "text"
      },
      "source": [
        "TRAIN VS TEST PERFORMANCE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe7BU9WOiXPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2kybIYRFkA_",
        "colab_type": "text"
      },
      "source": [
        "TOTAL LOSS, PRECISION AND RECALL VISUALIZED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF8GaQqOr7-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LXF8Q7sicFv",
        "colab_type": "text"
      },
      "source": [
        "# TOP 10 RECOMMENDATION GENERATOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzeFhOxkijL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movies_df = pd.read_csv('/content/gdrive/My Drive/CKME 136 Data Analytics - Capstone - Art Shablinski - 501009387/DATA/CLEAN DATA/movies_df.csv')\n",
        "\n",
        "# Select a random user and see the top recommendations based on the trained model:\n",
        "user_id = df.userId.sample(1).iloc[0]\n",
        "movies_watched_by_user = df[df.userId == user_id]\n",
        "movies_not_watched = movie_df[\n",
        "    ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
        "][\"movieId\"]\n",
        "movies_not_watched = list(\n",
        "    set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
        ")\n",
        "movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
        "user_encoder = user2user_encoded.get(user_id)\n",
        "user_movie_array = np.hstack(\n",
        "    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
        ")\n",
        "ratings = model.predict(user_movie_array).flatten()\n",
        "top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
        "recommended_movie_ids = [\n",
        "    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
        "]\n",
        "\n",
        "print(\"Showing recommendations for user: {}\".format(user_id))\n",
        "print(\"====\" * 9)\n",
        "print(\"Movies with high ratings from user\")\n",
        "print(\"----\" * 8)\n",
        "top_movies_user = (\n",
        "    movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
        "    .head(5)\n",
        "    .movieId.values\n",
        ")\n",
        "movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
        "for row in movie_df_rows.itertuples():\n",
        "    print(row.title, \":\", row.year, \":\", row.genres)\n",
        "\n",
        "print(\"----\" * 8)\n",
        "print(\"Top 10 movie recommendations\")\n",
        "print(\"----\" * 8)\n",
        "recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
        "for row in recommended_movies.itertuples():\n",
        "    print(row.title, \":\", row.year, \":\", row.genres)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}