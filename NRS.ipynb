{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_Collaborative_Filtering_Neural_Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiQDeKx9t7lD",
        "colab_type": "text"
      },
      "source": [
        "# **Niche Recommender System for Movies** ![Neural Nets](https://i.imgur.com/aa0fVPE.jpg1!)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnIFzLcolkxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4eea4ddc-d92e-48c6-b0d5-2c8f26c28efe"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "print(\"Run on TensorFlow 2.x\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run on TensorFlow 2.x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_WB-oukwREC",
        "colab_type": "text"
      },
      "source": [
        "# INITIAL STAGE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWpeh8XKVR_w",
        "colab_type": "text"
      },
      "source": [
        "IMPORT LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ostjpiswhkW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8d1ca0a9-08cf-45f1-e272-9e193b30ebfe"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from pathlib import Path\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# The following lines adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "# The following line improves formatting when ouputting NumPy arrays.\n",
        "np.set_printoptions(linewidth = 200)\n",
        "\n",
        "print(\"Imported modules.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Imported modules.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX0-0rIRVW3X",
        "colab_type": "text"
      },
      "source": [
        "INITIALIZE EAGER EXECUTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia2YW3yPVbwx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14e9a06c-f7fe-4aae-83f1-39e936955782"
      },
      "source": [
        "# After eager execution is enabled, operations are executed as they are defined \n",
        "# and Tensor objects hold concrete values.\n",
        "\n",
        "tf.compat.v1.enable_eager_execution(\n",
        "    config=None, device_policy=None, execution_mode=None\n",
        ")\n",
        "print(\"Eager Execution Enabled\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eager Execution Enabled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnA8yZc4v-7e",
        "colab_type": "text"
      },
      "source": [
        "LOADING DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lF9J29ewAdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Pre-processing of the data was done done in R, resulting in the following \n",
        "# training and test sets, which have been split randomly with 70/30 ratio:\n",
        "\n",
        "train_df = pd.read_csv(\"https://drive.google.com/file/d/1OfkihhKVTLVK_CGHFRj3ZzH63ty-xn0-/view?usp=sharing\", sep='delimiter', header=None)\n",
        "test_df = pd.read_csv(\"https://drive.google.com/file/d/1fTouaikZF3OMX1VTT77PmIXfNhBSjOpo/view?usp=sharing\", sep='delimiter', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL7mCShCbVXV",
        "colab_type": "text"
      },
      "source": [
        "DEFINE A PLOTTING FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjsNATjlbX-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6747f59-41de-458d-b955-4df639f15160"
      },
      "source": [
        "def plot_curve(epochs, hist, list_of_metrics):\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Value\")\n",
        "\n",
        "  for m in list_of_metrics:\n",
        "    x = hist[m]\n",
        "    plt.plot(epochs[1:], x[1:], label=m)\n",
        "\n",
        "  plt.legend()\n",
        "\n",
        "print(\"Loaded the plot_curve function.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded the plot_curve function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fytdF_0Kwe3Z",
        "colab_type": "text"
      },
      "source": [
        "# DEFINE THE MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCrpngW3RrY",
        "colab_type": "text"
      },
      "source": [
        "DEEP NEURAL NET TOPOGRAPHY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVseUiwDb6FF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "70d6910a-9929-45ac-90aa-b564cddaba41"
      },
      "source": [
        "def create_model(my_learning_rate):\n",
        "  # Destroys the current TF graph and session, and creates a new one.\n",
        "    tf.keras.backend.clear_session()\n",
        "  \n",
        "  # Initialize sequential model.\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Define the first hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=200, activation='relu'))\n",
        "    \n",
        "  # Define a dropout regularization layer. \n",
        "  model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "\n",
        "  # Define the second hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=200, activation='relu'))\n",
        "\n",
        "  # Define a dropout regularization layer. \n",
        "  model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "\n",
        "  # Define the output layer. The units parameter is set to 10 because\n",
        "  # the model must choose among 10 possible output values (representing\n",
        "  # users' ratings from 0.5 to 5, inclusive).\n",
        "  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))     \n",
        "                           \n",
        "  # Construct the layers into a model that TensorFlow can execute.  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model    \n",
        "\n",
        "\n",
        "def train_model(model, train_features, train_label, epochs,\n",
        "                batch_size=None, validation_split=0.2):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
        "                      epochs=epochs, shuffle=True, \n",
        "                      validation_split=validation_split)\n",
        " \n",
        "  # Tracking the progression of training.\n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  return epochs, hist    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-d3a45e270e65>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    model = tf.keras.models.Sequential()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3u9MeiXwkCp",
        "colab_type": "text"
      },
      "source": [
        "# BUILD AND TRAIN THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxmJM2sFyijS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tuning hyperparameters.\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "batch_size = 1000\n",
        "\n",
        "# Specify the label.\n",
        "label_name = \"ratings\"\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate, my_feature_layer)\n",
        "\n",
        "# Train the model on the training set.\n",
        "epochs, mse = train_model(my_model, train_df_norm, epochs, \n",
        "                          label_name, batch_size)\n",
        "plot_the_loss_curve(epochs, mse)\n",
        "\n",
        "# After building a model against the training set, testing the model\n",
        "# against the test set.\n",
        "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name))\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ISWEUpgjBfN",
        "colab_type": "text"
      },
      "source": [
        "# MEASURING PERFORMANCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh94MAaB0Uw7",
        "colab_type": "text"
      },
      "source": [
        "TRAINING AND VALIDATION LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHZzRRLc0ZWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}